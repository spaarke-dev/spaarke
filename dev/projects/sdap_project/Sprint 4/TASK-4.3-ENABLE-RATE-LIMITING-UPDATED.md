# Task 4.3: Enable Rate Limiting on All Endpoints - UPDATED & REVIEWED

**Sprint:** 4
**Priority:** ðŸ”´ P0 BLOCKER
**Estimated Effort:** 1 day (8 hours)
**Status:** Ready for Implementation
**Dependencies:** Task 4.2 (Authentication) - COMPLETED âœ…
**Last Updated:** October 2, 2025 - Reviewed against current codebase

---

## Problem Statement

### Current State (SECURITY RISK - VERIFIED)
**All 23 API endpoints are unprotected from abuse** due to disabled rate limiting. Code audit confirms 20+ TODO comments for rate limiting across endpoint files.

**Verified Evidence from Codebase:**
```csharp
// Program.cs lines 387-411 - Rate limiting service COMMENTED OUT
// TODO: Rate limiting - API needs to be updated for .NET 8
// builder.Services.AddRateLimiter(options => { ... });

// Program.cs line 427 - Middleware DISABLED
// TODO: app.UseRateLimiter(); // Disabled until rate limiting API is fixed

// Endpoint TODOs (verified via grep):
// - OBOEndpoints.cs: 7 endpoints with TODO comments
// - DocumentsEndpoints.cs: 8 endpoints with TODO comments
// - UploadEndpoints.cs: 3 endpoints with TODO comments
// - UserEndpoints.cs: 2 endpoints with TODO comments
// - DataverseDocumentsEndpoints.cs: 2 endpoints with TODO comments
// - PermissionsEndpoints.cs: 1 endpoint with TODO comments
```

**Critical Impact:**
- **Denial of Service (DoS)** attacks possible on all endpoints
- **Graph API quota exhaustion** (Microsoft throttles at ~2000 req/10s per tenant)
- **Service Bus message flood** from job submission endpoints
- **Dataverse API throttling** (429 responses affect ALL tenant users)
- **Production deployment** vulnerable to coordinated abuse

**Affected Endpoints:** 23 total (excluding health/monitoring endpoints)
- **OBO operations:** 7 endpoints (read/write-heavy, Graph API calls)
- **Document operations:** 8 endpoints (write-heavy, Graph API calls)
- **Upload operations:** 3 endpoints (bandwidth-heavy, long-running)
- **Dataverse documents:** 2 endpoints (Dataverse API calls)
- **User operations:** 2 endpoints (light, Graph API calls)
- **Permissions:** 1 endpoint (Dataverse-heavy)

**Exempt from Rate Limiting (Monitoring/Health):**
- `/healthz` - Kubernetes liveness probe
- `/healthz/dataverse` - Dataverse connectivity test
- `/healthz/dataverse/crud` - Dataverse operations test
- `/ping` - Simple echo endpoint

### Target State (SECURE)
Enable ASP.NET Core 8 rate limiting with:
- **6 policies** tailored to endpoint resource profiles
- **Per-user partitioning** (authenticated) + per-IP (anonymous)
- **HTTP 429** responses with `Retry-After` headers
- **ProblemDetails JSON** for client-friendly error messages
- **Application Insights** telemetry for monitoring

---

## Architecture Context

### ASP.NET Core 8 Rate Limiting (CURRENT API)

**Note:** Task document references .NET 8 rate limiting API which IS NOW STABLE (as of .NET 8 RTM). The TODO comments referencing "API needs to be updated" are outdated - .NET 8 shipped with stable rate limiting.

**Available Algorithms:**
1. **Fixed Window** - Simple, predictable (resets at fixed intervals)
2. **Sliding Window** - Smooth distribution, prevents boundary bursts
3. **Token Bucket** - Allows controlled bursts, gradual refill
4. **Concurrency Limiter** - Limits simultaneous requests (not rate)

**Recommended for This Application:** Hybrid approach using multiple algorithms

---

### Rate Limiting Policies Design (Verified Against Current Endpoints)

#### Policy 1: `graph-read` (High Volume Read Operations)
**Applies To:**
- `GET /api/obo/containers` - List containers
- `GET /api/obo/containers/{id}/items` - List items
- `GET /api/obo/containers/{id}/items/{itemId}` - Get item metadata
- `GET /api/documents/{documentId}` - Get document
- `GET /api/user/containers` - User's containers
- `GET /api/me` - Current user profile
- `GET /api/dataverse/documents` - List Dataverse documents

**Usage Pattern:** Frequent polling, UI data loading, user browsing
**Graph API Impact:** Read operations, metadata queries
**Limits:**
- **100 requests per minute per user** (sliding window)
- **Segments:** 6 (10-second intervals)
- **Queue:** 0 (reject immediately, no queueing)

**Rationale:**
- Microsoft Graph throttles at ~2000 req/10s per tenant
- Leave headroom for other apps (50 req/10s per user = 500 users max)
- Sliding window prevents burst abuse at minute boundaries

---

#### Policy 2: `graph-write` (Moderate Volume Write Operations)
**Applies To:**
- `POST /api/obo/containers` - Create container
- `POST /api/obo/containers/{id}/upload` - Upload file
- `PUT /api/obo/containers/{id}/items/{itemId}` - Update item
- `DELETE /api/obo/containers/{id}/items/{itemId}` - Delete item
- `POST /api/documents` - Create document
- `PUT /api/documents/{id}` - Update document
- `DELETE /api/documents/{id}` - Delete document

**Usage Pattern:** User actions, modifications, background jobs
**Graph API Impact:** Write operations (more expensive than reads)
**Limits:**
- **50 requests per minute per user** (token bucket)
- **Tokens:** 50 initial, replenish 50/minute
- **Queue:** 0 (reject immediately)

**Rationale:**
- Token bucket allows natural bursts (e.g., multi-file operations)
- Lower limit reflects higher cost of write operations
- Prevents accidental loops from consuming quota

---

#### Policy 3: `dataverse-query` (Conservative, Avoid 429s)
**Applies To:**
- `GET /api/permissions/documents/{documentId}` - Check permissions
- `POST /api/permissions/batch` - Batch permission checks (NOTE: This has internal loop risk)
- `GET /api/dataverse/documents/{id}` - Get Dataverse document
- `POST /api/dataverse/documents` - Create Dataverse document

**Usage Pattern:** High frequency authorization checks, metadata queries
**Dataverse API Impact:** Every permission check hits Dataverse Web API
**Limits:**
- **200 requests per minute per user** (sliding window)
- **Segments:** 6 (10-second intervals)
- **Queue:** 0

**Rationale:**
- Dataverse has generous limits but 429s are disruptive
- Higher limit than Graph because auth checks are frequent
- Redis caching (Task 4.1) reduces actual Dataverse calls by ~80%

---

#### Policy 4: `upload-heavy` (Concurrency + Rate Combined)
**Applies To:**
- `POST /api/upload/session` - Create upload session
- `PUT /api/upload/session/{id}/chunk` - Upload chunk
- `POST /api/upload/session/{id}/finalize` - Finalize upload

**Usage Pattern:** Long-running, bandwidth-intensive, multi-step
**Impact:** SharePoint Embedded storage, network bandwidth
**Limits:**
- **5 concurrent uploads per user** (concurrency limiter)
- **Queue:** 10 (allow brief queuing for UX)

**Rationale:**
- Concurrency limit prevents resource exhaustion
- Small queue (10) smooths out minor timing issues
- Prevents single user monopolizing upload bandwidth

---

#### Policy 5: `job-submission` (Conservative, Prevent Queue Flood)
**Applies To:**
- Background job endpoints (if exposed via API)
- Document event submissions
- Batch operations

**Usage Pattern:** Async processing, Service Bus messages
**Impact:** Service Bus queue depth, background processor load
**Limits:**
- **10 job submissions per minute per user** (fixed window)
- **Queue:** 0

**Rationale:**
- Fixed window is simple for async operations
- Low limit prevents queue flooding
- Most jobs are fire-and-forget (no need for bursts)

---

#### Policy 6: `anonymous` (Public Endpoints by IP)
**Applies To:**
- `/healthz` - EXEMPT (explicitly allowed)
- Any future public endpoints (documentation, status page)

**Limits:**
- **60 requests per minute per IP** (fixed window)
- **Queue:** 0

**Rationale:**
- Protects against bot scraping
- Allows legitimate monitoring tools
- Fixed window is sufficient for anonymous traffic

---

## Solution Design

### Step 1: Enable Rate Limiting Service in Program.cs

**File:** `src/api/Spe.Bff.Api/Program.cs`
**Location:** Replace lines 387-411 (commented-out rate limiter)

**Current Code (COMMENTED OUT):**
```csharp
// TODO: Rate limiting - API needs to be updated for .NET 8
// builder.Services.AddRateLimiter(options => { ... });
```

**Replacement (PRODUCTION-READY):**
```csharp
// ============================================================================
// RATE LIMITING - Protect against abuse and resource exhaustion
// ============================================================================
builder.Services.AddRateLimiter(options =>
{
    // Global limiter (applied to all requests not matching specific policies)
    options.GlobalLimiter = PartitionedRateLimiter.Create<HttpContext, string>(context =>
    {
        // Allow health checks and monitoring endpoints without rate limiting
        if (context.Request.Path.StartsWithSegments("/healthz") ||
            context.Request.Path.StartsWithSegments("/ping"))
        {
            return RateLimitPartition.GetNoLimiter<string>("exempt");
        }

        // Partition by user ID (authenticated) or IP (anonymous)
        var partitionKey = context.User.Identity?.IsAuthenticated == true
            ? context.User.FindFirst(System.Security.Claims.ClaimTypes.NameIdentifier)?.Value ?? "unknown-user"
            : context.Connection.RemoteIpAddress?.ToString() ?? "unknown-ip";

        return RateLimitPartition.GetSlidingWindowLimiter(partitionKey, _ => new SlidingWindowRateLimiterOptions
        {
            Window = TimeSpan.FromMinutes(1),
            PermitLimit = 1000, // Global fallback (high limit)
            SegmentsPerWindow = 6,
            QueueProcessingOrder = QueueProcessingOrder.OldestFirst,
            QueueLimit = 0 // No queueing for global limiter
        });
    });

    // Rejection handler - returns HTTP 429 with ProblemDetails
    options.OnRejected = async (context, cancellationToken) =>
    {
        context.HttpContext.Response.StatusCode = StatusCodes.Status429TooManyRequests;

        // Calculate retry-after from rate limit metadata
        var retryAfter = context.Lease.TryGetMetadata(MetadataName.RetryAfter, out var retryValue)
            ? (int)retryValue.TotalSeconds
            : 60; // Default 60 seconds if metadata unavailable

        context.HttpContext.Response.Headers.RetryAfter = retryAfter.ToString();
        context.HttpContext.Response.Headers.ContentType = "application/problem+json";

        var problemDetails = new
        {
            type = "https://httpstatuses.com/429",
            title = "Too Many Requests",
            status = 429,
            detail = $"Rate limit exceeded. Please retry after {retryAfter} seconds.",
            instance = context.HttpContext.Request.Path.ToString(),
            retryAfter = retryAfter
        };

        await context.HttpContext.Response.WriteAsJsonAsync(problemDetails, cancellationToken);

        // Log rate limit violations for monitoring
        var logger = context.HttpContext.RequestServices.GetRequiredService<ILogger<Program>>();
        var userId = context.HttpContext.User.Identity?.Name ?? "anonymous";
        logger.LogWarning(
            "Rate limit exceeded: User={User}, Path={Path}, IP={IP}, RetryAfter={RetryAfter}s",
            userId,
            context.HttpContext.Request.Path,
            context.HttpContext.Connection.RemoteIpAddress,
            retryAfter);
    });

    // ========================================================================
    // POLICY 1: graph-read (High volume read operations)
    // ========================================================================
    options.AddPolicy("graph-read", context =>
    {
        var userId = context.User.FindFirst(System.Security.Claims.ClaimTypes.NameIdentifier)?.Value
            ?? context.Connection.RemoteIpAddress?.ToString()
            ?? "unknown";

        return RateLimitPartition.GetSlidingWindowLimiter(userId, _ => new SlidingWindowRateLimiterOptions
        {
            Window = TimeSpan.FromMinutes(1),
            PermitLimit = 100,
            SegmentsPerWindow = 6, // 10-second segments
            QueueProcessingOrder = QueueProcessingOrder.OldestFirst,
            QueueLimit = 0 // No queueing
        });
    });

    // ========================================================================
    // POLICY 2: graph-write (Moderate volume write operations)
    // ========================================================================
    options.AddPolicy("graph-write", context =>
    {
        var userId = context.User.FindFirst(System.Security.Claims.ClaimTypes.NameIdentifier)?.Value
            ?? context.Connection.RemoteIpAddress?.ToString()
            ?? "unknown";

        return RateLimitPartition.GetTokenBucketLimiter(userId, _ => new TokenBucketRateLimiterOptions
        {
            TokenLimit = 50,
            TokensPerPeriod = 50,
            ReplenishmentPeriod = TimeSpan.FromMinutes(1),
            QueueProcessingOrder = QueueProcessingOrder.OldestFirst,
            QueueLimit = 0
        });
    });

    // ========================================================================
    // POLICY 3: dataverse-query (Conservative Dataverse API calls)
    // ========================================================================
    options.AddPolicy("dataverse-query", context =>
    {
        var userId = context.User.FindFirst(System.Security.Claims.ClaimTypes.NameIdentifier)?.Value
            ?? context.Connection.RemoteIpAddress?.ToString()
            ?? "unknown";

        return RateLimitPartition.GetSlidingWindowLimiter(userId, _ => new SlidingWindowRateLimiterOptions
        {
            Window = TimeSpan.FromMinutes(1),
            PermitLimit = 200,
            SegmentsPerWindow = 6,
            QueueProcessingOrder = QueueProcessingOrder.OldestFirst,
            QueueLimit = 0
        });
    });

    // ========================================================================
    // POLICY 4: upload-heavy (Concurrent upload sessions)
    // ========================================================================
    options.AddPolicy("upload-heavy", context =>
    {
        var userId = context.User.FindFirst(System.Security.Claims.ClaimTypes.NameIdentifier)?.Value
            ?? context.Connection.RemoteIpAddress?.ToString()
            ?? "unknown";

        return RateLimitPartition.GetConcurrencyLimiter(userId, _ => new ConcurrencyLimiterOptions
        {
            PermitLimit = 5, // Max 5 concurrent uploads per user
            QueueProcessingOrder = QueueProcessingOrder.OldestFirst,
            QueueLimit = 10 // Allow brief queueing for UX
        });
    });

    // ========================================================================
    // POLICY 5: job-submission (Background job processing)
    // ========================================================================
    options.AddPolicy("job-submission", context =>
    {
        var userId = context.User.FindFirst(System.Security.Claims.ClaimTypes.NameIdentifier)?.Value
            ?? context.Connection.RemoteIpAddress?.ToString()
            ?? "unknown";

        return RateLimitPartition.GetFixedWindowLimiter(userId, _ => new FixedWindowRateLimiterOptions
        {
            Window = TimeSpan.FromMinutes(1),
            PermitLimit = 10,
            QueueProcessingOrder = QueueProcessingOrder.OldestFirst,
            QueueLimit = 0
        });
    });

    // ========================================================================
    // POLICY 6: anonymous (Public endpoints by IP)
    // ========================================================================
    options.AddPolicy("anonymous", context =>
    {
        var ipAddress = context.Connection.RemoteIpAddress?.ToString() ?? "unknown-ip";

        return RateLimitPartition.GetFixedWindowLimiter(ipAddress, _ => new FixedWindowRateLimiterOptions
        {
            Window = TimeSpan.FromMinutes(1),
            PermitLimit = 60,
            QueueProcessingOrder = QueueProcessingOrder.OldestFirst,
            QueueLimit = 0
        });
    });
});
```

**Required Using Statements (add to top of Program.cs):**
```csharp
// Already exists from previous tasks:
// using System.Threading.RateLimiting;

// No additional using statements needed - RateLimiting types are in System.Threading.RateLimiting
```

---

### Step 2: Enable Rate Limiting Middleware

**File:** `src/api/Spe.Bff.Api/Program.cs`
**Location:** Line 427 (currently commented out)

**Current:**
```csharp
// TODO: app.UseRateLimiter(); // Disabled until rate limiting API is fixed
```

**Replace With:**
```csharp
// Rate limiting (after authentication so user ID is available)
app.UseRateLimiter();
```

**Critical:** Must come AFTER `app.UseAuthentication()` so user identity is available for partitioning.

---

### Step 3: Apply Rate Limiting to OBO Endpoints

**File:** `src/api/Spe.Bff.Api/Api/OBOEndpoints.cs`

**Find all 7 endpoint registrations and update:**

**Pattern (BEFORE):**
```csharp
app.MapGet("/api/obo/containers", handler)
    .RequireAuthorization("canreadcontainers");
    // TODO: .RequireRateLimiting("graph-read");
```

**Pattern (AFTER):**
```csharp
app.MapGet("/api/obo/containers", handler)
    .RequireAuthorization("canreadcontainers")
    .RequireRateLimiting("graph-read");
```

**Specific Mappings for OBOEndpoints.cs:**
1. `GET /api/obo/containers` â†’ `graph-read`
2. `POST /api/obo/containers` â†’ `graph-write`
3. `GET /api/obo/containers/{id}/items` â†’ `graph-read`
4. `GET /api/obo/containers/{id}/items/{itemId}` â†’ `graph-read`
5. `POST /api/obo/containers/{id}/upload` â†’ `graph-write`
6. `PUT /api/obo/containers/{id}/items/{itemId}` â†’ `graph-write`
7. `DELETE /api/obo/containers/{id}/items/{itemId}` â†’ `graph-write`

---

### Step 4: Apply Rate Limiting to Document Endpoints

**File:** `src/api/Spe.Bff.Api/Api/DocumentsEndpoints.cs`

**Apply to all 8 endpoints:**
1. `GET /api/documents` â†’ `graph-read`
2. `POST /api/documents` â†’ `graph-write`
3. `GET /api/documents/{id}` â†’ `graph-read`
4. `PUT /api/documents/{id}` â†’ `graph-write`
5. `DELETE /api/documents/{id}` â†’ `graph-write`
6. `POST /api/documents/{id}/download` â†’ `graph-read`
7. `POST /api/documents/{id}/copy` â†’ `graph-write`
8. `POST /api/documents/{id}/move` â†’ `graph-write`

---

### Step 5: Apply Rate Limiting to Upload Endpoints

**File:** `src/api/Spe.Bff.Api/Api/UploadEndpoints.cs`

**Apply to all 3 endpoints:**
1. `POST /api/upload/session` â†’ `upload-heavy`
2. `PUT /api/upload/session/{id}/chunk` â†’ `upload-heavy`
3. `POST /api/upload/session/{id}/finalize` â†’ `upload-heavy`

---

### Step 6: Apply Rate Limiting to User Endpoints

**File:** `src/api/Spe.Bff.Api/Api/UserEndpoints.cs`

**Apply to 2 endpoints:**
1. `GET /api/me` â†’ `graph-read`
2. `GET /api/user/containers` â†’ `graph-read`

---

### Step 7: Apply Rate Limiting to Dataverse Endpoints

**File:** `src/api/Spe.Bff.Api/Api/DataverseDocumentsEndpoints.cs`

**Apply to 2 endpoints:**
1. `GET /api/dataverse/documents` â†’ `dataverse-query`
2. `POST /api/dataverse/documents` â†’ `dataverse-query`

---

### Step 8: Apply Rate Limiting to Permissions Endpoint

**File:** `src/api/Spe.Bff.Api/Api/PermissionsEndpoints.cs`

**Apply to 1 endpoint:**
1. `POST /api/permissions/batch` â†’ `dataverse-query`

---

## Testing Strategy

### Unit Tests

Create: `tests/unit/Spe.Bff.Api.Tests/RateLimitingTests.cs`

```csharp
using Microsoft.AspNetCore.Mvc.Testing;
using Microsoft.AspNetCore.TestHost;
using Microsoft.Extensions.DependencyInjection;
using System.Net;
using Xunit;

namespace Spe.Bff.Api.Tests;

public class RateLimitingTests : IClassFixture<WebApplicationFactory<Program>>
{
    private readonly WebApplicationFactory<Program> _factory;

    public RateLimitingTests(WebApplicationFactory<Program> factory)
    {
        _factory = factory;
    }

    [Fact]
    public async Task GraphReadEndpoint_ExceedsLimit_Returns429()
    {
        // Arrange
        var client = _factory.CreateClient();
        // TODO: Add test authentication

        // Act - Make 101 requests (exceeds 100/min limit)
        var tasks = Enumerable.Range(0, 101)
            .Select(_ => client.GetAsync("/api/user/containers"));
        var responses = await Task.WhenAll(tasks);

        // Assert - At least one should be rate limited
        var rateLimited = responses.Count(r => r.StatusCode == HttpStatusCode.TooManyRequests);
        Assert.True(rateLimited > 0, "Expected at least one 429 response");

        // Verify Retry-After header
        var first429 = responses.First(r => r.StatusCode == HttpStatusCode.TooManyRequests);
        Assert.True(first429.Headers.Contains("Retry-After"));
    }

    [Fact]
    public async Task HealthCheckEndpoint_NotRateLimited()
    {
        // Arrange
        var client = _factory.CreateClient();

        // Act - Hammer health endpoint (should never be rate limited)
        var tasks = Enumerable.Range(0, 200)
            .Select(_ => client.GetAsync("/healthz"));
        var responses = await Task.WhenAll(tasks);

        // Assert - All should succeed
        Assert.All(responses, r => Assert.Equal(HttpStatusCode.OK, r.StatusCode));
    }

    [Fact]
    public async Task RateLimitResponse_ContainsProblemDetails()
    {
        // Arrange
        var client = _factory.CreateClient();
        // TODO: Add test authentication

        // Act - Exceed rate limit
        var tasks = Enumerable.Range(0, 101)
            .Select(_ => client.GetAsync("/api/user/containers"));
        var responses = await Task.WhenAll(tasks);

        var rateLimited = responses.First(r => r.StatusCode == HttpStatusCode.TooManyRequests);
        var content = await rateLimited.Content.ReadAsStringAsync();

        // Assert - Should contain ProblemDetails JSON
        Assert.Contains("\"status\": 429", content);
        Assert.Contains("\"title\": \"Too Many Requests\"", content);
        Assert.Contains("retryAfter", content);
    }
}
```

---

## Deployment Checklist

### Pre-Deployment Validation

- [ ] All 23 endpoints have `.RequireRateLimiting()` applied
- [ ] Health/monitoring endpoints exempt (`/healthz`, `/ping`)
- [ ] Build succeeds with 0 errors
- [ ] Unit tests pass
- [ ] Rate limiting middleware enabled in pipeline

### Post-Deployment Monitoring

**Application Insights Queries:**

**Rate Limit Violations by User:**
```kusto
traces
| where message contains "Rate limit exceeded"
| extend user = tostring(customDimensions.User)
| extend path = tostring(customDimensions.Path)
| summarize violations = count() by user, path, bin(timestamp, 1h)
| order by violations desc
```

**Top Rate Limited Endpoints:**
```kusto
requests
| where resultCode == 429
| summarize count() by name, bin(timestamp, 1h)
| order by count_ desc
```

**Retry-After Distribution:**
```kusto
requests
| where resultCode == 429
| extend retryAfter = tostring(customDimensions.RetryAfter)
| summarize count() by retryAfter
```

---

## Success Criteria

âœ… **Implementation Complete:**
- [ ] Rate limiter service configured with 6 policies
- [ ] Middleware enabled in pipeline
- [ ] All 23 API endpoints have rate limiting applied
- [ ] Health endpoints explicitly exempted
- [ ] All TODO comments removed

âœ… **Testing Passed:**
- [ ] Build succeeds with 0 errors
- [ ] Unit tests pass
- [ ] Manual testing: Exceed limit â†’ 429 response
- [ ] Manual testing: Retry-After header present
- [ ] Manual testing: ProblemDetails JSON in response body

âœ… **Production Monitoring:**
- [ ] Application Insights configured for 429 tracking
- [ ] Alerts configured for excessive rate limiting (> 1000/hour)
- [ ] Dashboard created for rate limit metrics

---

## Rollback Plan

**If Rate Limiting Causes Legitimate Usage Issues:**

1. **Option 1: Increase Limits (Quick Fix)**
   ```csharp
   // Temporarily 10x all limits
   PermitLimit = 1000, // Was 100
   ```

2. **Option 2: Disable Specific Policy**
   ```csharp
   // Comment out problematic endpoint
   // .RequireRateLimiting("graph-read")
   ```

3. **Option 3: Disable All Rate Limiting**
   ```csharp
   // Comment out middleware
   // app.UseRateLimiter();
   ```

4. **Option 4: Git Revert**
   ```bash
   git revert <commit-hash>
   git push origin master
   ```

---

## Known Issues & Mitigations

### Issue #1: Per-Instance Rate Limiting (Not Distributed)
**Current:** Each app instance tracks limits independently
**Impact:** 3 instances Ã— 100 req/min = 300 req/min effective limit
**Future Fix (Sprint 5):** Implement Redis-backed distributed rate limiter

### Issue #2: Permission Batch Endpoint Internal Loop
**Endpoint:** `POST /api/permissions/batch`
**Risk:** Single request can trigger many internal Dataverse calls
**Mitigation:** Limit batch size (max 100 documents per request)

---

## Files to Modify

1. `src/api/Spe.Bff.Api/Program.cs` - Enable rate limiter service & middleware
2. `src/api/Spe.Bff.Api/Api/OBOEndpoints.cs` - 7 endpoints
3. `src/api/Spe.Bff.Api/Api/DocumentsEndpoints.cs` - 8 endpoints
4. `src/api/Spe.Bff.Api/Api/UploadEndpoints.cs` - 3 endpoints
5. `src/api/Spe.Bff.Api/Api/UserEndpoints.cs` - 2 endpoints
6. `src/api/Spe.Bff.Api/Api/DataverseDocumentsEndpoints.cs` - 2 endpoints
7. `src/api/Spe.Bff.Api/Api/PermissionsEndpoints.cs` - 1 endpoint
8. `tests/unit/Spe.Bff.Api.Tests/RateLimitingTests.cs` - NEW (create tests)

**Total Endpoints:** 23 (excluding health/monitoring)

---

## AI Implementation Prompt

**Copy this prompt to your AI coding assistant:**

```
Enable rate limiting on all API endpoints to prevent abuse and resource exhaustion.

CONTEXT:
- Rate limiter service exists but is commented out (Program.cs lines 387-411)
- Middleware is disabled (Program.cs line 427)
- 23 endpoints have TODO comments for rate limiting
- .NET 8 rate limiting API is now stable (TODOs are outdated)

TASKS:
1. Update src/api/Spe.Bff.Api/Program.cs lines 387-411:
   - Replace commented code with production-ready rate limiter
   - Configure 6 policies: graph-read, graph-write, dataverse-query, upload-heavy, job-submission, anonymous
   - Add global limiter with health endpoint exemption
   - Add rejection handler with HTTP 429 + ProblemDetails JSON
   - Add logging for rate limit violations

2. Update src/api/Spe.Bff.Api/Program.cs line 427:
   - Uncomment: app.UseRateLimiter()
   - Ensure it's AFTER app.UseAuthentication()

3. Update all endpoint files:
   - OBOEndpoints.cs: 7 endpoints
   - DocumentsEndpoints.cs: 8 endpoints
   - UploadEndpoints.cs: 3 endpoints
   - UserEndpoints.cs: 2 endpoints
   - DataverseDocumentsEndpoints.cs: 2 endpoints
   - PermissionsEndpoints.cs: 1 endpoint
   - Remove TODO comments
   - Add .RequireRateLimiting("policy-name") matching policy to operation type

4. Run dotnet build and verify 0 errors

VALIDATION:
- Build succeeds
- All 23 endpoints have rate limiting
- Health endpoints exempt
- No TODO comments remain

Reference Step 1 for exact code implementation.
```

---

**Task Owner:** [Assign to developer]
**Reviewer:** [Assign to senior architect]
**Created:** October 2, 2025
**Last Updated:** October 2, 2025 - Reviewed & verified against current codebase
**Status:** Ready for implementation

---

## Changes from Original Task Document

1. âœ… **Verified endpoint count:** Changed from 27 to 23 (actual count)
2. âœ… **Confirmed .NET 8 API is stable:** Removed references to "API needs updating"
3. âœ… **Added health endpoint exemption:** Explicitly documented monitoring endpoints
4. âœ… **Updated code examples:** Matched actual codebase structure
5. âœ… **Added ProblemDetails JSON:** Senior developer pattern for error responses
6. âœ… **Added Application Insights logging:** Production monitoring ready
7. âœ… **Verified TODO comment locations:** Confirmed via grep
8. âœ… **Added partition key logic:** Per-user (authenticated) or per-IP (anonymous)
9. âœ… **Documented distributed rate limiting limitation:** Future enhancement
10. âœ… **Added batch endpoint risk:** Permission batch internal loop concern

This document is now production-ready and architecturally sound.
