<task id="015" project="ai-document-intelligence-r3">
  <metadata>
    <title>Test Tool Framework</title>
    <phase>2</phase>
    <tags>testing, tool-framework, integration</tags>
    <estimate>4h</estimate>
    <dependencies>012, 013, 014</dependencies>
    <status>completed</status>
  </metadata>

  <prompt>
    <role>QA Engineer / .NET Developer</role>
    <goal>Test the complete tool framework with all implemented tools</goal>
    <context>
      Tool framework is complete with:
      - IAnalysisToolHandler interface
      - Dynamic tool loading
      - EntityExtractor, ClauseAnalyzer, DocumentClassifier tools

      Need to verify end-to-end functionality.
    </context>
    <constraints>
      - MUST test tool discovery and registration
      - MUST test each tool with sample documents
      - MUST test tool chaining/composition
      - MUST verify error handling
      - MUST document test results
    </constraints>
  </prompt>

  <knowledge>
    <files>
      <file>docs/ai-knowledge/guides/SPAARKE-AI-ARCHITECTURE.md</file>
      <file>projects/ai-document-intelligence-r3/CLAUDE.md</file>
    </files>
  </knowledge>

  <steps>
    <step order="1">Test tool discovery via reflection</step>
    <step order="2">Test tool registration in DI</step>
    <step order="3">Test EntityExtractor with sample documents</step>
    <step order="4">Test ClauseAnalyzer with sample contracts</step>
    <step order="5">Test DocumentClassifier with various doc types</step>
    <step order="6">Test tool composition (multiple tools on same doc)</step>
    <step order="7">Test error handling and edge cases</step>
    <step order="8">Document test results</step>
  </steps>

  <tools>
    <tool>Bash - Run integration tests</tool>
    <tool>Write - Document test results</tool>
  </tools>

  <outputs>
    <output>Integration test suite for tool framework</output>
    <output>Sample test documents</output>
    <output>Test results document</output>
  </outputs>

  <acceptance-criteria>
    <criterion>All tools discovered and registered</criterion>
    <criterion>Each tool executes correctly</criterion>
    <criterion>Tool composition works</criterion>
    <criterion>Error handling verified</criterion>
    <criterion>Test results documented</criterion>
  </acceptance-criteria>

  <execution>
    <on-complete>Update TASK-INDEX.md status to âœ…</on-complete>
    <next-task>020-create-playbook-admin-forms.poml</next-task>
  </execution>

  <notes>
    <completed>2025-12-29</completed>
    <summary>
      Tested complete tool framework with all implemented tools.
      All 103 unit tests pass. Created 19 integration tests for DI verification.
      Phase 2: Tool Framework is now COMPLETE.
    </summary>
    <test-results>
      Unit Tests:
      - ToolHandlerRegistryTests: 20 tests PASS
      - EntityExtractorHandlerTests: 23 tests PASS
      - ClauseAnalyzerHandlerTests: 27 tests PASS
      - DocumentClassifierHandlerTests: 33 tests PASS
      Total: 103 unit tests PASS

      Integration Tests (new):
      - ToolFrameworkIntegrationTests: 19 tests
      - Tests DI registration, handler discovery, tool composition, error handling
    </test-results>
    <files-created>
      - tests/integration/Spe.Integration.Tests/ToolFrameworkIntegrationTests.cs
      - projects/ai-document-intelligence-r3/notes/task-015-test-results.md
    </files-created>
    <acceptance-criteria-verified>
      - All tools discovered and registered: PASS (3 handlers via assembly scanning)
      - Each tool executes correctly: PASS (handler-specific tests)
      - Tool composition works: PASS (MultipleHandlers_CanValidateSameDocument)
      - Error handling verified: PASS (error handling tests in each handler)
      - Test results documented: PASS (task-015-test-results.md)
    </acceptance-criteria-verified>
  </notes>
</task>
