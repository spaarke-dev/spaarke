<task id="005" project="ai-document-intelligence-r3">
  <metadata>
    <title>Add Redis Caching for Embeddings</title>
    <phase>1</phase>
    <tags>redis, caching, embeddings, performance</tags>
    <estimate>4h</estimate>
    <dependencies>004</dependencies>
    <status>completed</status>
  </metadata>

  <prompt>
    <role>Senior .NET Developer</role>
    <goal>Implement Redis caching for embeddings to reduce Azure OpenAI costs and latency</goal>
    <context>
      Embedding generation is expensive (API cost) and slow (network latency).
      Cache embeddings by content hash to avoid regenerating for same content.
      Must follow ADR-009 Redis-first caching patterns.
    </context>
    <constraints>
      - MUST cache embeddings by content hash
      - MUST use Redis as primary cache (ADR-009)
      - MUST set appropriate TTL (balance freshness vs cost)
      - MUST handle cache misses gracefully
      - MUST NOT use hybrid L1 cache unless profiling proves need
    </constraints>
  </prompt>

  <knowledge>
    <files>
      <file>docs/reference/adr/ADR-009-redis-first-caching.md</file>
      <file>docs/ai-knowledge/patterns/distributed-cache.md</file>
    </files>
  </knowledge>

  <steps>
    <step order="1">Create content hashing utility for cache keys</step>
    <step order="2">Implement IEmbeddingCache interface</step>
    <step order="3">Create RedisEmbeddingCache implementation</step>
    <step order="4">Integrate cache into RagService embedding generation</step>
    <step order="5">Configure TTL based on embedding stability</step>
    <step order="6">Add cache hit/miss telemetry</step>
    <step order="7">Write unit tests with mock cache</step>
  </steps>

  <tools>
    <tool>Read - Review existing Redis usage patterns</tool>
    <tool>Write - Create cache implementation</tool>
    <tool>Bash - Run tests</tool>
  </tools>

  <outputs>
    <output>IEmbeddingCache.cs - Cache interface</output>
    <output>RedisEmbeddingCache.cs - Redis implementation</output>
    <output>ContentHasher.cs - Hashing utility</output>
    <output>Cache integration in RagService</output>
    <output>Unit tests</output>
  </outputs>

  <acceptance-criteria>
    <criterion>Embeddings cached by content hash</criterion>
    <criterion>Redis used as cache store</criterion>
    <criterion>Cache hit/miss metrics logged</criterion>
    <criterion>TTL configured appropriately</criterion>
    <criterion>Tests pass</criterion>
  </acceptance-criteria>

  <execution>
    <on-complete>Update TASK-INDEX.md status to ✅</on-complete>
    <next-task>006-test-shared-deployment-model.poml</next-task>
  </execution>

  <notes>
    <completion-date>2025-12-29</completion-date>
    <summary>Implemented Redis-based embedding cache following GraphTokenCache patterns (ADR-009).</summary>
    <findings>
      <finding type="created">src/server/api/Sprk.Bff.Api/Services/Ai/IEmbeddingCache.cs - Interface with content hashing and caching methods</finding>
      <finding type="created">src/server/api/Sprk.Bff.Api/Services/Ai/EmbeddingCache.cs - Redis implementation with SHA256 hashing, 7-day TTL, graceful error handling</finding>
      <finding type="created">tests/unit/Sprk.Bff.Api.Tests/Services/Ai/EmbeddingCacheTests.cs - 21 unit tests</finding>
      <finding type="modified">src/server/api/Sprk.Bff.Api/Services/Ai/RagService.cs - Integrated IEmbeddingCache into SearchAsync and GetEmbeddingAsync</finding>
      <finding type="modified">src/server/api/Sprk.Bff.Api/Program.cs - DI registration for IEmbeddingCache</finding>
      <finding type="modified">tests/unit/Sprk.Bff.Api.Tests/Services/Ai/RagServiceTests.cs - Added IEmbeddingCache mock, 8 new cache-related tests</finding>
      <finding type="note">Cache key format: sdap:embedding:{SHA256-base64-hash}</finding>
      <finding type="note">TTL: 7 days - embeddings are deterministic for same content + model</finding>
      <finding type="note">Serialization: float[] → byte[] via Buffer.BlockCopy (efficient binary)</finding>
      <finding type="note">Graceful error handling: cache failures don't break embedding generation</finding>
      <finding type="note">Uses existing CacheMetrics with cacheType="embedding" for OpenTelemetry</finding>
    </findings>
  </notes>
</task>
