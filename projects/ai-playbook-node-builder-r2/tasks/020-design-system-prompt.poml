<?xml version="1.0" encoding="UTF-8"?>
<task id="020" project="ai-chat-playbook-builder">
  <metadata>
    <title>Design system prompt for canvas building</title>
    <phase>3</phase>
    <tags>ai, prompt-engineering</tags>
    <estimate>1d</estimate>
    <dependencies>none</dependencies>
    <status>completed</status>
  </metadata>

  <prompt>
    <goal>Design the system prompt that guides the AI in building playbook canvases.</goal>
    <context>
      The system prompt must:
      - Define all 11 intent categories
      - Explain available tools and when to use them
      - Set confidence thresholds for clarification
      - Include canvas state awareness
    </context>
    <constraints>
      - Constrained output format for reliable parsing
      - Include validation rules
    </constraints>
  </prompt>

  <knowledge>
    <files>
      <file path="projects/ai-playbook-node-builder-r2/ai-chat-playbook-builder.md" reason="Intent categories" />
    </files>
  </knowledge>

  <steps>
    <step order="1">Define system prompt structure</step>
    <step order="2">Document all 11 intent categories</step>
    <step order="3">Define tool usage guidelines</step>
    <step order="4">Add canvas state context section</step>
    <step order="5">Add output format specification</step>
    <step order="6">Test prompt with sample inputs</step>
  </steps>

  <tools>
    <tool name="Write">Create prompt files</tool>
  </tools>

  <outputs>
    <output type="file">src/server/api/Sprk.Bff.Api/Services/Ai/Prompts/PlaybookBuilderSystemPrompt.cs</output>
  </outputs>

  <acceptance-criteria>
    <criterion>System prompt covers all 11 intents</criterion>
    <criterion>Tool usage clearly documented</criterion>
    <criterion>Output format is parseable</criterion>
    <criterion>Test inputs produce expected outputs</criterion>
  </acceptance-criteria>

  <notes>
    <completed-date>2026-01-16</completed-date>
    <summary>
      Created comprehensive PlaybookBuilderSystemPrompt.cs with:

      1. INTENT CLASSIFICATION PROMPT:
         - All 11 intent categories documented with descriptions and triggers
         - CREATE_PLAYBOOK, ADD_NODE, REMOVE_NODE, CONNECT_NODES
         - CONFIGURE_NODE, LINK_SCOPE, CREATE_SCOPE, QUERY_STATUS
         - MODIFY_LAYOUT, UNDO, UNCLEAR

      2. ENTITY EXTRACTION:
         - Node entities (nodeType, nodeId, nodeLabel, position)
         - Scope entities (scopeType, scopeId, scopeName)
         - Connection entities (sourceNode, targetNode)
         - Configuration entities (configKey, configValue, outputVariable)

      3. TOOL EXECUTION PROMPT (8 tools):
         - addNode: Create node with type, label, position, config
         - removeNode: Delete node by ID
         - createEdge: Connect source to target
         - updateNodeConfig: Modify node properties
         - linkScope: Attach Action/Skill/Knowledge/Tool
         - createScope: Create new Dataverse scope record
         - searchScopes: Find existing scopes by query
         - autoLayout: Arrange nodes visually

      4. BUILD PLAN GENERATION PROMPT:
         - Node type documentation
         - Common playbook patterns (Lease, Contract, Risk)
         - Structured build plan JSON format
         - Scope requirements section

      5. SCOPE RECOMMENDATION PROMPT:
         - Matching criteria per scope type
         - Scoring 0.0-1.0 with thresholds
         - Create suggestion when no match

      6. PLAYBOOK EXPLANATION PROMPT:
         - Full playbook overview format
         - Node-specific explanations
         - Scope explanations

      7. CANVAS STATE AWARENESS:
         - CanvasContext class for state tracking
         - BuildCompletePrompt() method for dynamic context
         - BuildCanvasContextSection() for state formatting

      8. CONFIDENCE THRESHOLDS:
         - IntentConfidence: 0.75
         - EntityConfidence: 0.80
         - ScopeMatchScore: 0.70

      9. OUTPUT FORMAT:
         - Valid JSON structure for all responses
         - Clarification format with options
         - Error response format

      10. ACCEPTANCE CRITERIA MET:
          - ✅ System prompt covers all 11 intents
          - ✅ Tool usage clearly documented (8 tools with examples)
          - ✅ Output format is parseable JSON
          - ✅ Structure enables testing with sample inputs
    </summary>
  </notes>
</task>
